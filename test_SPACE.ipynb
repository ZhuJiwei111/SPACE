{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load preprocess data: /home/jiwei_zhu/disk/Enformer/Data/data//human_test_196608_False_False.bin\n",
      "load preprocess data: /home/jiwei_zhu/disk/Enformer/Data/data//mouse_test_196608_False_False.bin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import kipoiseq\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dataloaders.h5dataset import GEPBedDataset, MultiSpeciesDataset\n",
    "\n",
    "human_test_data_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/human_test.h5\"\n",
    "human_test_bed_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/human_test.bed\"\n",
    "human_genome_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/hg38.ml.fa\"\n",
    "\n",
    "mouse_test_data_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/mouse_test.h5\"\n",
    "mouse_test_bed_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/mouse_test.bed\"\n",
    "mouse_genome_path: str = \"/home/jiwei_zhu/disk/Enformer/Data/mm10.fa\"\n",
    "\n",
    "df_human = pd.read_csv(\"/home/jiwei_zhu/disk/Enformer/enformer_MoE/targets_human_sorted.txt\", sep=\"\\t\")\n",
    "df_mouse = pd.read_csv(\"/home/jiwei_zhu/disk/Enformer/enformer_MoE/targets_mouse_sorted.txt\", sep=\"\\t\")\n",
    "\n",
    "index_human = list(df_human[\"index\"])\n",
    "track_types_human = {\n",
    "    \"DNASE/ATAC\": (0, 684),\n",
    "    \"TF ChIP-seq\": (684, 2573),\n",
    "    \"Histone ChIP-seq\": (2573, 4675),\n",
    "    \"CAGE\": (4675, 5313),\n",
    "}\n",
    "index_mouse = list(df_mouse[\"index\"])\n",
    "track_types_mouse = {\n",
    "    \"DNASE/ATAC\": (0, 228),\n",
    "    \"TF ChIP-seq\": (228, 519),\n",
    "    \"Histone ChIP-seq\": (519, 1286),\n",
    "    \"CAGE\": (1286, 1643),\n",
    "}\n",
    "\n",
    "test_dataset = MultiSpeciesDataset(\n",
    "    file_paths = [human_test_data_path, mouse_test_data_path],\n",
    "    bed_paths = [human_test_bed_path, mouse_test_bed_path],\n",
    "    seqlen = 131072,\n",
    "    genome_paths = [human_genome_path, mouse_genome_path],\n",
    "    shift_aug = False,\n",
    "    rc_aug = False,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiwei_zhu/conda_envs/enformer/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model.modeling_space import Space, SpaceConfig, TrainingSpace\n",
    "\n",
    "model_path = \"./results/Space_species_tracks/checkpoint-28000\"\n",
    "config = SpaceConfig.from_pretrained(os.path.join(model_path, \"config.json\"))\n",
    "model = TrainingSpace(config)\n",
    "state_dict = torch.load(os.path.join(model_path, \"pytorch_model.bin\"))\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    key = key.replace(\"enformer\", \"model\")\n",
    "    if key == \"model.tracks.output.human.weight\":\n",
    "        key = \"model.heads.human.0.weight\"\n",
    "    if key == \"model.tracks.output.human.bias\":\n",
    "        key = \"model.heads.human.0.bias\"\n",
    "    if key == \"model.tracks.output.mouse.weight\":\n",
    "        key = \"model.heads.mouse.0.weight\"\n",
    "    if key == \"model.tracks.output.mouse.bias\":\n",
    "        key = \"model.heads.mouse.0.bias\"\n",
    "    new_state_dict[key] = value\n",
    "state_dict = new_state_dict\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "is_species = True\n",
    "is_tracks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr_coef_per_track(x, y, dim=0):\n",
    "    x_centered = x - x.mean(dim=dim, keepdim=True)\n",
    "    y_centered = y - y.mean(dim=dim, keepdim=True)\n",
    "    corr = F.cosine_similarity(x_centered, y_centered, dim=dim)\n",
    "    return corr\n",
    "\n",
    "\n",
    "def pearson_corr_coef(x, y, dim=1, reduce_dims=(-1,)):\n",
    "    x_centered = x - x.mean(dim=dim, keepdim=True)\n",
    "    y_centered = y - y.mean(dim=dim, keepdim=True)\n",
    "    return F.cosine_similarity(x_centered, y_centered, dim=dim).mean(dim=reduce_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 1937, Mouse: 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2017/2017 [12:08<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 0.6062219410165414\n",
      "Mouse: 0.7155115181523855\n",
      "torch.Size([1937, 896, 5313]) torch.Size([1937, 896, 5313]) torch.Size([2017, 896, 1643]) torch.Size([2017, 896, 1643])\n"
     ]
    }
   ],
   "source": [
    "depth = 11\n",
    "species_num_experts = 4\n",
    "tracks_num_experts = 8\n",
    "\n",
    "pres_human, pres_mouse = [], []\n",
    "target_human, target_mouse = [], []\n",
    "p_human, p_mouse = 0.0, 0.0\n",
    "gates_human, gates_mouse = np.zeros((depth, species_num_experts)), np.zeros((depth, species_num_experts))\n",
    "weights_human, weights_mouse = np.zeros((1, tracks_num_experts)), np.zeros((1, tracks_num_experts))\n",
    "total_gates = np.zeros((8, tracks_num_experts))\n",
    "\n",
    "model.eval()\n",
    "len_human, len_mouse = len(test_dataset.human_dataset), len(test_dataset.mouse_dataset)\n",
    "print(f\"Human: {len_human}, Mouse: {len_mouse}\")\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    data = test_dataset[idx]\n",
    "    human_x = torch.tensor(data[\"human_x\"], dtype=torch.float32).to(device)\n",
    "    mouse_x = torch.tensor(data[\"mouse_x\"], dtype=torch.float32).to(device)\n",
    "    human_labels = torch.tensor(data[\"human_labels\"][:, index_human], dtype=torch.float32).to(device)\n",
    "    mouse_labels = torch.tensor(data[\"mouse_labels\"][:, index_mouse], dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(human_x, mouse_x)\n",
    "        pre_human = predictions[\"human\"][\"out\"][:, index_human]\n",
    "        pre_mouse = predictions[\"mouse\"][\"out\"][:, index_mouse]\n",
    "        \n",
    "        if idx < len_human:\n",
    "            p_human += pearson_corr_coef(pre_human, human_labels).cpu().item()\n",
    "            pres_human.append(pre_human.cpu())\n",
    "            target_human.append(human_labels.cpu())\n",
    "        if idx < len_mouse:\n",
    "            p_mouse += pearson_corr_coef(pre_mouse, mouse_labels).cpu().item()\n",
    "            pres_mouse.append(pre_mouse.cpu())\n",
    "            target_mouse.append(mouse_labels.cpu())\n",
    "        if is_species:\n",
    "            gates_human += np.array([tensor.cpu().numpy() for tensor in predictions[\"human\"][\"species\"][\"gates\"]])\n",
    "            gates_mouse += np.array([tensor.cpu().numpy() for tensor in predictions[\"mouse\"][\"species\"][\"gates\"]])\n",
    "        if is_tracks:\n",
    "            tracks_gates = {f\"{species} {key}\":  value for species in [\"human\", \"mouse\"] for key, value in predictions[species][\"tracks\"][\"gates\"].items()}\n",
    "            tracks_gates = {key: value.cpu().numpy() for key, value in tracks_gates.items()}\n",
    "            tracks_gates = np.stack(list(tracks_gates.values()))\n",
    "            total_gates += tracks_gates\n",
    "            weights_human += predictions[\"human\"][\"tracks\"][\"weights\"].cpu().numpy()\n",
    "            weights_mouse += predictions[\"mouse\"][\"tracks\"][\"weights\"].cpu().numpy()\n",
    "\n",
    "p_human /= len_human\n",
    "p_mouse /= len_mouse\n",
    "print(f\"Human: {p_human}\")\n",
    "print(f\"Mouse: {p_mouse}\")\n",
    "if is_species:\n",
    "    gates_human /= gates_human.sum(axis=1, keepdims=True)\n",
    "    gates_mouse /= gates_mouse.sum(axis=1, keepdims=True)\n",
    "    species_gates = np.stack((gates_human, gates_mouse), axis=1)\n",
    "    np.save(\"./temp/species_gates.npy\", species_gates)\n",
    "if is_tracks:\n",
    "    np.save(\"./temp/tracks_gates.npy\", total_gates)\n",
    "\n",
    "pres_human = torch.stack(pres_human)\n",
    "target_human = torch.stack(target_human)\n",
    "pres_mouse = torch.stack(pres_mouse)\n",
    "target_mouse = torch.stack(target_mouse)\n",
    "torch.save(pres_human, \"./temp/pres_human.pt\")\n",
    "torch.save(target_human, \"./temp/target_human.pt\")\n",
    "torch.save(pres_mouse, \"./temp/pres_mouse.pt\")\n",
    "torch.save(target_mouse, \"./temp/target_mouse.pt\")\n",
    "print(pres_human.shape, target_human.shape, pres_mouse.shape, target_mouse.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pres_human = torch.load(\"./temp/pres_human.pt\")\n",
    "pres_mouse = torch.load(\"./temp/pres_mouse.pt\")\n",
    "target_human = torch.load(\"./temp/target_human.pt\")\n",
    "target_mouse = torch.load(\"./temp/target_mouse.pt\")\n",
    "print(pres_human.shape, pres_mouse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n",
      "DNASE/ATAC: 0.8182075023651123\n",
      "TF ChIP-seq: 0.5456007719039917\n",
      "Histone ChIP-seq: 0.6641464829444885\n",
      "CAGE: 0.6319071054458618\n",
      "Mouse:\n",
      "DNASE/ATAC: 0.7835639119148254\n",
      "TF ChIP-seq: 0.5928989052772522\n",
      "Histone ChIP-seq: 0.7853987812995911\n",
      "CAGE: 0.6393424868583679\n"
     ]
    }
   ],
   "source": [
    "def pearsonr(x, y):\n",
    "    # 计算均值\n",
    "    x_mean = x.mean(dim=0, keepdim=True)\n",
    "    y_mean = y.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # 中心化\n",
    "    x_centered = x - x_mean\n",
    "    y_centered = y - y_mean\n",
    "\n",
    "    # 计算协方差\n",
    "    covariance = (x_centered * y_centered).sum(dim=0)\n",
    "\n",
    "    # 计算标准差\n",
    "    x_std = torch.sqrt((x_centered**2).sum(dim=0))\n",
    "    y_std = torch.sqrt((y_centered**2).sum(dim=0))\n",
    "\n",
    "    # 计算 Pearson 相关性\n",
    "    corr = covariance / (x_std * y_std)\n",
    "\n",
    "    return corr\n",
    "\n",
    "pre_human_flatten = pres_human.view(-1, 5313)\n",
    "targets_human_flatten = target_human.view(-1, 5313)\n",
    "tracks_pre_human = {key: pre_human_flatten[:, start:end] for key, (start, end) in track_types_human.items()}\n",
    "tracks_target_human = {key: targets_human_flatten[:, start:end] for key, (start, end) in track_types_human.items()}\n",
    "\n",
    "pre_mouse_flatten = pres_mouse.view(-1, 1643)\n",
    "targets_mouse_flatten = target_mouse.view(-1, 1643)\n",
    "tracks_pre_mouse = {key: pre_mouse_flatten[:, start:end] for key, (start, end) in track_types_mouse.items()}\n",
    "tracks_target_mouse = {key: targets_mouse_flatten[:, start:end] for key, (start, end) in track_types_mouse.items()}\n",
    "\n",
    "corr_human = {}\n",
    "for track in track_types_human.keys():\n",
    "    p, l = tracks_pre_human[track], tracks_target_human[track]\n",
    "    if track == \"CAGE\":\n",
    "        p, l = torch.log(p + 1), torch.log(l + 1)\n",
    "    corr_human[track] = pearsonr(p, l)\n",
    "corr_mouse = {}  \n",
    "for track in track_types_mouse.keys():\n",
    "    p, l = tracks_pre_mouse[track], tracks_target_mouse[track]\n",
    "    if track == \"CAGE\":\n",
    "        p, l = torch.log(p + 1), torch.log(l + 1)\n",
    "    corr_mouse[track] = pearsonr(p, l)\n",
    "\n",
    "print(\"Human:\")\n",
    "for key, value in corr_human.items():\n",
    "    print(f\"{key}: {value.mean()}\")\n",
    "\n",
    "print(\"Mouse:\")\n",
    "for key, value in corr_mouse.items():\n",
    "    print(f\"{key}: {value.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./temp/corr_human_space.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corr_human, f)\n",
    "\n",
    "with open(\"./temp/corr_mouse_space.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corr_mouse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "species_gates = np.load(\"./temp/species_gates.npy\")\n",
    "is_species = True\n",
    "show_gates = 100 * species_gates\n",
    "plt.figure(figsize=(4, 2))\n",
    "sns.heatmap(\n",
    "    show_gates[-1],\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar=False,\n",
    "    yticklabels=[\"Human\", \"Mouse\"],\n",
    ")\n",
    "\n",
    "plt.savefig(\"./temp/species_gates.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_species:\n",
    "    # 绘制SpeciesMoE门控网络图\n",
    "    gates_path = \"./version/5/4.28000.png\"\n",
    "    show_gates = 100 * species_gates\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(10, 8)) \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(11):  \n",
    "        sns.heatmap(show_gates[i], ax=axes[i], cmap=\"Blues\", annot=True, fmt=\".2f\", cbar=False, yticklabels=[\"Human\", \"Mouse\"])\n",
    "        axes[i].set_title(f\"Transformer Block {i+1}\")\n",
    "        axes[i].set_xlabel(\"Experts\")\n",
    "        axes[i].set_ylabel(\"Species\")\n",
    "\n",
    "    # 隐藏多余的子图\n",
    "    for j in range(11, 12): \n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(gates_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_gates = np.load(\"./temp/tracks_gates.npy\")\n",
    "is_tracks = True\n",
    "if is_tracks:\n",
    "    temp1, temp2 =tracks_gates[0:4], tracks_gates[4:8]\n",
    "    tracks_gates = temp1 + temp2\n",
    "    tracks_gates = tracks_gates / tracks_gates.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # 绘制门控网络图\n",
    "    gates_path = \"./version/5/4.28000_tracks.png\"\n",
    "    show_gates = 100 * tracks_gates\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    labels = [\n",
    "        \"DNASE/ATAC\",\n",
    "        \"TF ChIP-seq\",\n",
    "        \"Histone ChIP-seq\",\n",
    "        \"CAGE\",\n",
    "    ]\n",
    "    sns.heatmap(show_gates, annot=True, fmt=\".2f\", cmap=\"Blues\", linewidths=0.5, cbar=False, yticklabels=labels)\n",
    "\n",
    "    plt.savefig(\"./temp/tracks_gate.png\", dpi=500, bbox_inches=\"tight\")\n",
    "    # plt.savefig(gates_path)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
